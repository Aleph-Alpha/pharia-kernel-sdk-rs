package pharia:skill@0.2.7;

@since(version = 0.1.0)
world skill {
    @since(version = 0.1.0)
    import csi;
    @since(version = 0.1.0)
    export skill-handler;
}

@since(version = 0.1.0)
interface skill-handler {
    /// The set of errors which may be raised by functions in this interface
    @since(version = 0.1.0)
    variant error {
        internal(string),
        invalid-input(string)
    }

    @since(version = 0.1.0)
    run: func(input: list<u8>) -> result<list<u8>, error>;
}

// A WASI interface dedicated to interacting with Large Language Models and other AI-related tasks.
@since(version = 0.1.0)
interface csi {
    /// The reason the model finished generating
    @since(version = 0.1.0)
    enum finish-reason {
        /// The model hit a natural stopping point or a provided stop sequence
        stop,
        /// The maximum number of tokens specified in the request was reached
        length,
        /// Content was omitted due to a flag from content filters
        content-filter,
    }

    /// The result of a completion, including the text generated as well as
    /// why the model finished completing.
    @since(version = 0.1.0)
    record completion {
        /// The text generated by the model
        text: string,
        /// The reason the model finished generating
        finish-reason: finish-reason,
    }

    /// Completion request parameters
    @since(version = 0.2.0)
    record completion-params {
        /// The maximum tokens that should be inferred.
        ///
        /// Note: the backing implementation may return less tokens due to
        /// other stop reasons.
        max-tokens: option<u32>,
        /// The randomness with which the next token is selected.
        temperature: option<f64>,
        /// The number of possible next tokens the model will choose from.
        top-k: option<u32>,
        /// The probability total of next tokens the model will choose from.
        top-p: option<f64>,
        /// A list of sequences that, if encountered, the API will stop generating further tokens.
        stop: list<string>,
    }

    @since(version = 0.2.0)
    complete: func(model: string, prompt: string, params: completion-params) -> completion;

    @since(version = 0.2.7)
    enum role {
        user,
        assistant,
        system,
    }

    @since(version = 0.2.7)
    record message {
        role: role,
        content: string,
    }

    @since(version = 0.2.7)
    record chat-params {
        /// The maximum tokens that should be inferred.
        ///
        /// Note: the backing implementation may return less tokens due to
        /// other stop reasons.
        max-tokens: option<u32>,
        /// The randomness with which the next token is selected.
        temperature: option<f64>,
        /// The probability total of next tokens the model will choose from.
        top-p: option<f64>,
    }

    /// The result of a chat reponse, including the message generated as well as
    /// why the model finished completing.
    @since(version = 0.2.7)
    record chat-response {
        /// The message generated by the model
        message: message,
        /// The reason the model finished generating
        finish-reason: finish-reason,
    }

    @since(version = 0.2.7)
    chat: func(model: string, messages: list<message>, params: chat-params) -> chat-response;

    /// Chunking parameters
    @since(version = 0.2.1)
    record chunk-params {
        /// The name of the model the chunk is intended to be used for.
        /// This must be a known model.
        model: string,
        /// The maximum number of tokens that should be returned per chunk.
        max-tokens: u32,
    }

    @since(version = 0.2.1)
    chunk: func(text: string, params: chunk-params) -> list<string>;

    /// ISO 639-3
    @since(version = 0.2.2)
    enum language {
        /// English
        eng,
        /// German
        deu,
    }

    /// Select the detected language for the provided input based on the list of possible languages.
    /// If no language matches, None is returned.
    ///
    /// text: Text input
    /// languages: All languages that should be considered during detection.
    @since(version = 0.2.2)
    select-language: func(text: string, languages: list<language>) -> option<language>;

    /// Completion request parameters
    @since(version = 0.2.3)
    record completion-request {
        model: string,
        prompt: string,
        params: completion-params
    }

    @since(version = 0.2.3)
    complete-all: func(requests: list<completion-request>) -> list<completion>;

    /// Which documents you want to search in, and which type of index should be used
    record index-path {
        /// The namespace the collection belongs to
        namespace: string,
        /// The collection you want to search in
        collection: string,
        /// The search index you want to use for the collection
         index: string,
    }

    record document-path {
        namespace: string,
        collection: string,
        name: string,
    }

    record search-result {
        document-path: document-path,
        content: string,
        score: f64,
    }

    search: func(index-path: index-path, query: string, max-results: u32, min-score: option<f64>) -> list<search-result>;
}
