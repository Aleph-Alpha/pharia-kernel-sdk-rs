package pharia:skill@0.2.0;

@since(version = 0.1.0)
world skill {
    @since(version = 0.1.0)
	import csi;
	@since(version = 0.1.0)
	export skill-handler;
}

@since(version = 0.1.0)
interface skill-handler {
	/// The set of errors which may be raised by functions in this interface
	@since(version = 0.1.0)
	variant error {
		internal(string),
		invalid-input(string)
	}

	@since(version = 0.1.0)
	run: func(input: list<u8>) -> result<list<u8>, error>;
}

// A WASI interface dedicated to interacting with Large Language Models and other AI-related tasks.
@since(version = 0.1.0)
interface csi {
	/// The reason the model finished generating
	@since(version = 0.1.0)
	enum finish-reason {
		/// The model hit a natural stopping point or a provided stop sequence
		stop,
		/// The maximum number of tokens specified in the request was reached
		length,
		/// Content was omitted due to a flag from content filters
		content-filter,
	}

	/// The result of a completion, including the text generated as well as
	/// why the model finished completing.
	@since(version = 0.1.0)
	record completion {
		/// The text generated by the model
		text: string,
		/// The reason the model finished generating
		finish-reason: finish-reason,
	}

	/// Completion request parameters
	@since(version = 0.2.0)
	record completion-params {
		/// The maximum tokens that should be inferred.
		///
		/// Note: the backing implementation may return less tokens due to
		/// other stop reasons.
		max-tokens: option<u32>,
		/// The randomness with which the next token is selected.
		temperature: option<float64>,
		/// The number of possible next tokens the model will choose from.
		top-k: option<u32>,
		/// The probability total of next tokens the model will choose from.
		top-p: option<float64>,
		/// A list of sequences that, if encountered, the API will stop generating further tokens.
		stop: list<string>,
	}

	@since(version = 0.2.0)
	complete: func(model: string, prompt: string, params: completion-params) -> completion;
}
